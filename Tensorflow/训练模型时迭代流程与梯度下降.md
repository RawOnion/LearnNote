![](https://cdn.jsdelivr.net/gh/RawOnion/imgcloud/img/训练模型一般流程1.png)

在机器学习中，**超参数**是在开始学习过程**之前**设置值的参数，而不是通过训练得到的参数数据。

通常情况下，需要对超参数进行优化,选择一组好的超参数，可以提高学习的性能和效果。 

**超参数**是编程人员在机器学习算法中用于调整的旋钮

**典型超参数：** 学习率、神经网络的隐含层数量······



# 梯度下降

**梯度**：一个向量（矢量），表示某一函数在该点处的**方向导数**沿着该方向取得**最大值**，即函数在该点处沿着该方向（此时梯度的方向）变化最快,变化率最大。还可以这么理解梯度，根据梯度计算的结果，可以判断哪个自变量的变化对因变量影响最大。即理解梯度的两个角度：

1. 沿着哪个方向因变量增长的最快；
2. 哪个自变量变化对因变量影响最大。



梯度下降算法：

> Compute $\nabla C$
>
> Small step in $-\nabla C$ direction
>
> Repeat.



**深度学习本质上是在解空间中寻找能使损失函数最小化的解**，而这个解在实际工程中就是模型里面的参数和偏置。从函数的角度来看，自变量就是这些参数和偏置，通过不停的迭代，找到解使得因变量最小。而模型的输入只不过是常量。

![](https://cdn.jsdelivr.net/gh/RawOnion/imgcloud/img/梯度下降.jpg)

梯度下降的图解，它的自变量`x`、`y`轴是参数，因变量`z`轴是损失函数的结果。梯度下降优化的最终目的是找到损失函数的极小值。